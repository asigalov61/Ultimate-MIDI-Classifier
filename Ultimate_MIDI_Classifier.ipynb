{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "642b1fba-5bc8-49fe-a1b7-3ef1748c47e1",
      "metadata": {
        "id": "642b1fba-5bc8-49fe-a1b7-3ef1748c47e1"
      },
      "source": [
        "# Ultimate MIDI Classifier (ver. 1.0)\n",
        "\n",
        "***\n",
        "\n",
        "Powered by tegridy-tools: https://github.com/asigalov61/tegridy-tools\n",
        "\n",
        "***\n",
        "\n",
        "WARNING: This complete implementation is a functioning model of the Artificial Intelligence. Please excercise great humility, care, and respect. https://www.nscai.gov/\n",
        "\n",
        "***\n",
        "\n",
        "#### Project Los Angeles\n",
        "\n",
        "#### Tegridy Code 2024\n",
        "\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (SETUP ENVIRONMENT)"
      ],
      "metadata": {
        "id": "sS-jnN3cE1vD"
      },
      "id": "sS-jnN3cE1vD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cdce86d-c8b6-4185-82ee-b03165824d99",
      "metadata": {
        "id": "2cdce86d-c8b6-4185-82ee-b03165824d99",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Install all dependencies\n",
        "!git clone --depth 1 https://github.com/asigalov61/Ultimate-MIDI-Classifier\n",
        "!pip install einops\n",
        "!pip install torch-summary\n",
        "!apt install fluidsynth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a67680de-b150-4839-af1e-130e9dbefc8e",
      "metadata": {
        "id": "a67680de-b150-4839-af1e-130e9dbefc8e",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Import modules\n",
        "\n",
        "print('=' * 70)\n",
        "print('Loading modules...')\n",
        "print('=' * 70)\n",
        "\n",
        "import os\n",
        "import statistics\n",
        "import re\n",
        "import tqdm\n",
        "\n",
        "import torch\n",
        "\n",
        "%cd /content/Ultimate-MIDI-Classifier\n",
        "\n",
        "import TMIDIX\n",
        "\n",
        "from x_transformer_1_23_2 import *\n",
        "\n",
        "from midi_to_colab_audio import midi_to_colab_audio\n",
        "\n",
        "%cd /content/\n",
        "\n",
        "import random\n",
        "\n",
        "from torchsummary import summary\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics\n",
        "\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "print('=' * 70)\n",
        "print('Done')\n",
        "print('=' * 70)\n",
        "print('Torch version:', torch.__version__)\n",
        "print('=' * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (LOAD LABELS AND FUNCTIONS)"
      ],
      "metadata": {
        "id": "EDKw2VxsC0Ao"
      },
      "id": "EDKw2VxsC0Ao"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ca6e21c-d9f0-4694-ae10-ebd1c1c7b8e0",
      "metadata": {
        "id": "8ca6e21c-d9f0-4694-ae10-ebd1c1c7b8e0",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Load Ultimate MIDI Classifier labels and helper functions\n",
        "\n",
        "#===============================================================================\n",
        "# Helper functions\n",
        "#===============================================================================\n",
        "\n",
        "def str_strip_song(string):\n",
        "  if string is not None:\n",
        "    string = string.replace('-', ' ').replace('_', ' ').replace('=', ' ')\n",
        "    str1 = re.compile('[^a-zA-Z ]').sub('', string)\n",
        "    return re.sub(' +', ' ', str1).strip().title()\n",
        "  else:\n",
        "    return ''\n",
        "\n",
        "def str_strip_artist(string):\n",
        "  if string is not None:\n",
        "    string = string.replace('-', ' ').replace('_', ' ').replace('=', ' ')\n",
        "    str1 = re.compile('[^0-9a-zA-Z ]').sub('', string)\n",
        "    return re.sub(' +', ' ', str1).strip().title()\n",
        "  else:\n",
        "    return ''\n",
        "\n",
        "def song_artist_to_song_artist_tokens(file_name):\n",
        "    idx = classifier_labels.index(file_name)\n",
        "\n",
        "    tok1 = idx // 424\n",
        "    tok2 = idx % 424\n",
        "\n",
        "    return [tok1, tok2]\n",
        "\n",
        "def song_artist_tokens_to_song_artist(file_name_tokens):\n",
        "\n",
        "    tok1 = file_name_tokens[0]\n",
        "    tok2 = file_name_tokens[1]\n",
        "\n",
        "    idx = (tok1 * 424) + tok2\n",
        "\n",
        "    return classifier_labels[idx]\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "print('=' * 70)\n",
        "print('Loading Ultimate MIDI Classifier labels...')\n",
        "print('=' * 70)\n",
        "classifier_labels = TMIDIX.Tegridy_Any_Pickle_File_Reader('/content/Ultimate-MIDI-Classifier/Data/Ultimate_MIDI_Classifier_Song_Artist_Labels')\n",
        "print('=' * 70)\n",
        "genre_labels = TMIDIX.Tegridy_Any_Pickle_File_Reader('/content/Ultimate-MIDI-Classifier/Data/Ultimate_MIDI_Classifier_Music_Genre_Labels')\n",
        "genre_labels_fnames = [f[0] for f in genre_labels]\n",
        "print('=' * 70)\n",
        "print('Done!')\n",
        "print('=' * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (LOAD MODEL)"
      ],
      "metadata": {
        "id": "_ouQn7fvEBzS"
      },
      "id": "_ouQn7fvEBzS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd32281d-4b91-4dec-8e74-9e01224e205a",
      "metadata": {
        "id": "dd32281d-4b91-4dec-8e74-9e01224e205a",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Load Ultimate MIDI Classifier Pre-Trained Model\n",
        "\n",
        "model_precision = \"bfloat16\" # @param [\"bfloat16\", \"float16\", \"float32\"]\n",
        "plot_tokens_embeddings = True # @param {type:\"boolean\"}\n",
        "\n",
        "print('=' * 70)\n",
        "print('Setting-up Ultimate MIDI Classifier model...')\n",
        "print('Please wait...')\n",
        "print('=' * 70)\n",
        "\n",
        "model_path = '/content/Ultimate-MIDI-Classifier/Model/Ultimate_MIDI_Classifier_Trained_Model_29886_steps_0.556_loss_0.8339_acc.pth'\n",
        "\n",
        "if os.path.isfile(model_path):\n",
        "  print('Model already exists...')\n",
        "\n",
        "else:\n",
        "  hf_hub_download(repo_id='asigalov61/Ultimate-MIDI-Classifier',\n",
        "                  filename='Ultimate_MIDI_Classifier_Trained_Model_29886_steps_0.556_loss_0.8339_acc.pth',\n",
        "                  local_dir='/content/Ultimate-MIDI-Classifier/Model',\n",
        "                  )\n",
        "\n",
        "print('=' * 70)\n",
        "print('Instantiating model...')\n",
        "\n",
        "device_type = 'cuda'\n",
        "\n",
        "if model_precision == 'bfloat16' and torch.cuda.is_bf16_supported():\n",
        "  dtype = 'bfloat16'\n",
        "else:\n",
        "  dtype = 'float16'\n",
        "\n",
        "if model_precision == 'float16':\n",
        "  dtype = 'float16'\n",
        "\n",
        "if model_precision == 'float32':\n",
        "  dtype = 'float32'\n",
        "\n",
        "ptdtype = {'float32': torch.float32, 'bfloat16': torch.bfloat16, 'float16': torch.float16}[dtype]\n",
        "ctx = torch.amp.autocast(device_type=device_type, dtype=ptdtype)\n",
        "\n",
        "SEQ_LEN = 1026 # Models seq len (must be divisible by 4)\n",
        "PAD_IDX = 940 # Models pad index\n",
        "\n",
        "# instantiate the model\n",
        "\n",
        "model = TransformerWrapper(\n",
        "    num_tokens = PAD_IDX+1,\n",
        "    max_seq_len = SEQ_LEN,\n",
        "    attn_layers = Decoder(dim = 1024, depth = 24, heads = 32, attn_flash = True)\n",
        ")\n",
        "\n",
        "model = AutoregressiveWrapper(model, ignore_index=PAD_IDX, pad_value=PAD_IDX)\n",
        "\n",
        "model = torch.nn.DataParallel(model)\n",
        "\n",
        "model.cuda()\n",
        "print('=' * 70)\n",
        "\n",
        "print('Loading model checkpoint...')\n",
        "\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "print('=' * 70)\n",
        "\n",
        "model.eval()\n",
        "\n",
        "print('Done!')\n",
        "print('=' * 70)\n",
        "\n",
        "print('Model will use', dtype, 'precision...')\n",
        "print('=' * 70)\n",
        "\n",
        "# Model stats\n",
        "print('Model summary...')\n",
        "summary(model)\n",
        "\n",
        "if plot_tokens_embeddings:\n",
        "\n",
        "  tok_emb = model.module.net.token_emb.emb.weight.detach().cpu().tolist()\n",
        "\n",
        "  cos_sim = metrics.pairwise_distances(\n",
        "    tok_emb, metric='cosine'\n",
        "  )\n",
        "  plt.figure(figsize=(7, 7))\n",
        "  plt.imshow(cos_sim, cmap=\"inferno\", interpolation=\"nearest\")\n",
        "  im_ratio = cos_sim.shape[0] / cos_sim.shape[1]\n",
        "  plt.colorbar(fraction=0.046 * im_ratio, pad=0.04)\n",
        "  plt.xlabel(\"Position\")\n",
        "  plt.ylabel(\"Position\")\n",
        "  plt.tight_layout()\n",
        "  plt.plot()\n",
        "  plt.savefig(\"/content/Ultimate-MIDI-Classifier-Tokens-Embeddings-Plot.png\", bbox_inches=\"tight\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (LOAD SOURCE MIDI)"
      ],
      "metadata": {
        "id": "2B9hDOHz2kdA"
      },
      "id": "2B9hDOHz2kdA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73b7564c-45dd-48bb-a638-e551178d35ee",
      "metadata": {
        "id": "73b7564c-45dd-48bb-a638-e551178d35ee",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Load a MIDI file to classify\n",
        "full_path_to_MIDI_file = \"/content/Ultimate-MIDI-Classifier/Seeds/Come To My Window.mid\" # @param {type:\"string\"}\n",
        "\n",
        "print('=' * 70)\n",
        "print('Loading MIDI file...')\n",
        "\n",
        "midi_name = os.path.basename(full_path_to_MIDI_file).split('.')[0]\n",
        "\n",
        "raw_score = TMIDIX.midi2single_track_ms_score(full_path_to_MIDI_file)\n",
        "\n",
        "#===============================================================================\n",
        "# Enhanced score notes\n",
        "\n",
        "escore_notes = TMIDIX.advanced_score_processor(raw_score, return_enhanced_score_notes=True)[0]\n",
        "\n",
        "if len(escore_notes) > 0:\n",
        "\n",
        "    #=======================================================\n",
        "    # PRE-PROCESSING\n",
        "\n",
        "    #===============================================================================\n",
        "    # Augmented enhanced score notes\n",
        "\n",
        "    escore_notes = TMIDIX.augment_enhanced_score_notes(escore_notes, timings_divider=32)\n",
        "\n",
        "    escore_notes = [e for e in escore_notes if e[6] < 80 or e[6] == 128]\n",
        "\n",
        "    #=======================================================\n",
        "    # Augmentation\n",
        "\n",
        "    #=======================================================\n",
        "    # FINAL PROCESSING\n",
        "\n",
        "    melody_chords = []\n",
        "\n",
        "    #=======================================================\n",
        "    # MAIN PROCESSING CYCLE\n",
        "    #=======================================================\n",
        "\n",
        "    pe = escore_notes[0]\n",
        "\n",
        "    pitches = []\n",
        "\n",
        "    notes_counter = 0\n",
        "\n",
        "    for e in escore_notes:\n",
        "\n",
        "        #=======================================================\n",
        "        # Timings...\n",
        "\n",
        "        delta_time = max(0, min(127, e[1]-pe[1]))\n",
        "\n",
        "        if delta_time != 0:\n",
        "            pitches = []\n",
        "\n",
        "        # Durations and channels\n",
        "\n",
        "        dur = max(1, min(127, e[2]))\n",
        "\n",
        "        # Patches\n",
        "        pat = max(0, min(128, e[6]))\n",
        "\n",
        "        # Pitches\n",
        "\n",
        "        if pat == 128:\n",
        "            ptc = max(1, min(127, e[4]))+128\n",
        "        else:\n",
        "            ptc = max(1, min(127, e[4]))\n",
        "\n",
        "        #=======================================================\n",
        "        # FINAL NOTE SEQ\n",
        "\n",
        "        # Writing final note synchronously\n",
        "\n",
        "        if ptc not in pitches:\n",
        "            melody_chords.extend([delta_time, dur+128, ptc+256])\n",
        "            pitches.append(ptc)\n",
        "            notes_counter += 1\n",
        "\n",
        "        pe = e\n",
        "\n",
        "#==============================================================\n",
        "\n",
        "print('Done!')\n",
        "print('=' * 70)\n",
        "print('Composition has', notes_counter, 'notes')\n",
        "print('=' * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (CLASSIFY)"
      ],
      "metadata": {
        "id": "U-lCX8aRGiWm"
      },
      "id": "U-lCX8aRGiWm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84f1c2d6-95e8-47eb-9d4e-868436d201a4",
      "metadata": {
        "id": "84f1c2d6-95e8-47eb-9d4e-868436d201a4",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Classify MIDI\n",
        "\n",
        "# @markdown You can stop classification at any time to render partial results\n",
        "classification_sampling_resolution = 2 # @param {type:\"slider\", min:1, max:5, step:1}\n",
        "\n",
        "print('=' * 70)\n",
        "print('Ultimate MIDI Classifier')\n",
        "print('=' * 70)\n",
        "\n",
        "print('Input MIDI file name:', midi_name)\n",
        "print('=' * 70)\n",
        "print('Sampling score...')\n",
        "\n",
        "chunk_size = 1020\n",
        "\n",
        "score = melody_chords\n",
        "\n",
        "input_data = []\n",
        "\n",
        "for i in range(0, len(score)-chunk_size, chunk_size // classification_sampling_resolution):\n",
        "    schunk = score[i:i+chunk_size]\n",
        "\n",
        "    if len(schunk) == chunk_size:\n",
        "\n",
        "        td = [937]\n",
        "\n",
        "        td.extend(schunk)\n",
        "\n",
        "        td.extend([938])\n",
        "\n",
        "        input_data.append(td)\n",
        "\n",
        "print('Done!')\n",
        "print('=' * 70)\n",
        "print('Composition was split into' , len(input_data), 'samples', 'of 340 notes each with', 340 - chunk_size // classification_sampling_resolution // 3, 'notes overlap')\n",
        "print('=' * 70)\n",
        "print('Number of notes in all composition samples:', len(input_data) * 340)\n",
        "print('=' * 70)\n",
        "\n",
        "#==============================================================\n",
        "\n",
        "print('Classifying...')\n",
        "print('=' * 70)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "model.eval()\n",
        "\n",
        "artist_results = []\n",
        "song_results = []\n",
        "\n",
        "results = []\n",
        "\n",
        "for input in tqdm.tqdm(input_data):\n",
        "\n",
        "  try:\n",
        "\n",
        "    x = torch.tensor(input[:1022], dtype=torch.long, device='cuda')\n",
        "\n",
        "    with ctx:\n",
        "      out = model.module.generate(x,\n",
        "                                  2,\n",
        "                                  filter_logits_fn=top_k,\n",
        "                                  filter_kwargs={'k': 1},\n",
        "                                  temperature=0.9,\n",
        "                                  return_prime=False,\n",
        "                                  verbose=False)\n",
        "\n",
        "    result = tuple(out[0].tolist())\n",
        "\n",
        "    results.append(result)\n",
        "\n",
        "  except KeyboardInterrupt:\n",
        "    print('Stopping...')\n",
        "    break\n",
        "\n",
        "  except Exception as ex:\n",
        "    print('Error!')\n",
        "    print(ex)\n",
        "    break\n",
        "\n",
        "final_result = statistics.mode(results)\n",
        "\n",
        "print('=' * 70)\n",
        "print('Done!')\n",
        "print('=' * 70)\n",
        "\n",
        "result_toks = [final_result[0]-512, final_result[1]-512]\n",
        "song_artist = song_artist_tokens_to_song_artist(result_toks)\n",
        "gidx = genre_labels_fnames.index(song_artist)\n",
        "genre = genre_labels[gidx][1]\n",
        "\n",
        "print('Most common classification genre label:', genre)\n",
        "print('Most common classification song-artist label:', song_artist)\n",
        "print('Most common song-artist classification label ratio:' , results.count(final_result) / len(results))\n",
        "print('=' * 70)\n",
        "\n",
        "print('All classification labels summary:')\n",
        "print('=' * 70)\n",
        "\n",
        "all_artists_labels = []\n",
        "\n",
        "for i, res in enumerate(results):\n",
        "  result_toks = [res[0]-512, res[1]-512]\n",
        "  song_artist = song_artist_tokens_to_song_artist(result_toks)\n",
        "  gidx = genre_labels_fnames.index(song_artist)\n",
        "  genre = genre_labels[gidx][1]\n",
        "  print('Notes', i*170, '-', (i*170)+340, '===', genre, '---', song_artist)\n",
        "\n",
        "  artist_label = str_strip_artist(song_artist.split(' --- ')[1])\n",
        "\n",
        "  all_artists_labels.append(artist_label)\n",
        "\n",
        "print('=' * 70)\n",
        "\n",
        "mode_artist_label = statistics.mode(all_artists_labels)\n",
        "mode_artist_label_count = all_artists_labels.count(mode_artist_label)\n",
        "\n",
        "print('Aggregated artist classification label:', mode_artist_label)\n",
        "print('Aggregated artist classification label ratio:', mode_artist_label_count / len(all_artists_labels))\n",
        "\n",
        "print('=' * 70)\n",
        "print('Done!')\n",
        "print('=' * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (GENERATE)"
      ],
      "metadata": {
        "id": "echJkNeg6Lt5"
      },
      "id": "echJkNeg6Lt5"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Generate classified music composition\n",
        "\n",
        "#@markdown NOTE: You can stop the generation at any time to render partial results\n",
        "\n",
        "start_from = \"scratch\" # @param [\"scratch\", \"loaded_MIDI\"]\n",
        "number_of_blocks_to_generate = 2 # @param {type:\"slider\", min:1, max:25, step:1}\n",
        "model_sampling_top_k_value = 25 # @param {type:\"slider\", min:1, max:50, step:1}\n",
        "render_MIDI_to_audio = True # @param {type:\"boolean\"}\n",
        "\n",
        "print('=' * 70)\n",
        "print('Ultimate MIDI Classifier Music Generator')\n",
        "print('=' * 70)\n",
        "\n",
        "all_composition_classification_labels = []\n",
        "\n",
        "print('Generating prime block...')\n",
        "\n",
        "if start_from == \"scratch\":\n",
        "  x = torch.tensor([[937]], dtype=torch.long, device='cuda')\n",
        "\n",
        "else:\n",
        "  x = torch.tensor([input_data[0][:511]], dtype=torch.long, device='cuda')\n",
        "\n",
        "with ctx:\n",
        "  out = model.module.generate(x,\n",
        "                              1021-x.shape[1],\n",
        "                              filter_logits_fn=top_k,\n",
        "                              filter_kwargs={'k': model_sampling_top_k_value},\n",
        "                              temperature=0.9,\n",
        "                              return_prime=True,\n",
        "                              verbose=False)\n",
        "\n",
        "prime_output = out.tolist()[0]\n",
        "\n",
        "print('=' * 70)\n",
        "print('Classifiying prime block...')\n",
        "\n",
        "\n",
        "x = torch.tensor([prime_output+[938]], dtype=torch.long, device='cuda')\n",
        "\n",
        "with ctx:\n",
        "  out = model.module.generate(x,\n",
        "                              2,\n",
        "                              filter_logits_fn=top_k,\n",
        "                              filter_kwargs={'k': 1},\n",
        "                              temperature=0.9,\n",
        "                              return_prime=False,\n",
        "                              verbose=False)\n",
        "\n",
        "prime_output_cls = out.tolist()[0]\n",
        "\n",
        "result_toks = [prime_output_cls[0]-512, prime_output_cls[1]-512]\n",
        "song_artist = song_artist_tokens_to_song_artist(result_toks)\n",
        "gidx = genre_labels_fnames.index(song_artist)\n",
        "genre = genre_labels[gidx][1]\n",
        "\n",
        "all_composition_classification_labels.append(genre + ' --- ' + song_artist)\n",
        "\n",
        "print('=' * 70)\n",
        "print('Prime block classification genre label:', genre)\n",
        "print('Prime block classification song-artist label:', song_artist)\n",
        "print('=' * 70)\n",
        "\n",
        "print('Continuing generation...')\n",
        "print('=' * 70)\n",
        "\n",
        "output = []\n",
        "output.extend(prime_output)\n",
        "\n",
        "for i in range(number_of_blocks_to_generate):\n",
        "\n",
        "  try:\n",
        "\n",
        "    print('Generating block #', i+1)\n",
        "\n",
        "    x = torch.tensor([[937] + output[-513:-3]], dtype=torch.long, device='cuda')\n",
        "\n",
        "    with ctx:\n",
        "      out = model.module.generate(x,\n",
        "                                  1021-x.shape[1],\n",
        "                                  filter_logits_fn=top_k,\n",
        "                                  filter_kwargs={'k': model_sampling_top_k_value},\n",
        "                                  temperature=0.9,\n",
        "                                  return_prime=False,\n",
        "                                  verbose=False)\n",
        "\n",
        "    outy = out.tolist()[0]\n",
        "    output.extend(outy)\n",
        "\n",
        "    print('=' * 70)\n",
        "    print('Classifiying block #', i+1)\n",
        "\n",
        "    x = torch.tensor([output[-1021:]+[938]], dtype=torch.long, device='cuda')\n",
        "\n",
        "    with ctx:\n",
        "      out = model.module.generate(x,\n",
        "                                  2,\n",
        "                                  filter_logits_fn=top_k,\n",
        "                                  filter_kwargs={'k': 1},\n",
        "                                  temperature=0.9,\n",
        "                                  return_prime=False,\n",
        "                                  verbose=False)\n",
        "\n",
        "    output_cls = out.tolist()[0]\n",
        "\n",
        "    result_toks = [output_cls[0]-512, output_cls[1]-512]\n",
        "    song_artist = song_artist_tokens_to_song_artist(result_toks)\n",
        "    gidx = genre_labels_fnames.index(song_artist)\n",
        "    genre = genre_labels[gidx][1]\n",
        "\n",
        "    all_composition_classification_labels.append(genre + ' --- ' + song_artist)\n",
        "\n",
        "    print('=' * 70)\n",
        "    print('Block #', i+1, 'classification genre label:', genre)\n",
        "    print('Block #', i+1, 'classification song-artist label:', song_artist)\n",
        "    print('=' * 70)\n",
        "\n",
        "  except KeyboardInterrupt:\n",
        "    print('Stopping...')\n",
        "    print('=' * 70)\n",
        "    break\n",
        "\n",
        "  except Exception as ex:\n",
        "    print('Error!')\n",
        "    print(ex)\n",
        "    break\n",
        "\n",
        "print('Converting generated blocks to MIDI...')\n",
        "print('=' * 70)\n",
        "\n",
        "print('Sample INTs', output[:15])\n",
        "\n",
        "if len(output) != 0:\n",
        "\n",
        "    song = output\n",
        "    song_f = []\n",
        "\n",
        "    time = 0\n",
        "    dur = 0\n",
        "    vel = 90\n",
        "    pitch = 0\n",
        "    channel = 0\n",
        "\n",
        "    for ss in song:\n",
        "\n",
        "        if 0 <= ss < 128:\n",
        "\n",
        "            time += ss * 32\n",
        "\n",
        "        if 128 < ss < 256:\n",
        "\n",
        "            dur = (ss-128) * 32\n",
        "\n",
        "        if 256 < ss < 512:\n",
        "\n",
        "            chan = (ss-256) // 128\n",
        "\n",
        "            if chan == 1:\n",
        "                channel = 9\n",
        "            else:\n",
        "                channel = 0\n",
        "\n",
        "            pitch = (ss-256) % 128\n",
        "\n",
        "            if channel == 0:\n",
        "              vel = max(40, pitch)\n",
        "              song_f.append(['note', time, dur, channel, pitch, vel, 0])\n",
        "            else:\n",
        "              vel = [110, 120][pitch % 2]\n",
        "              song_f.append(['note', time, dur, channel, pitch, vel, 128])\n",
        "\n",
        "detailed_stats = TMIDIX.Tegridy_ms_SONG_to_MIDI_Converter(song_f,\n",
        "                                                        output_signature = 'Ultimate MIDI Classifier',\n",
        "                                                        output_file_name = '/content/Ultimate-MIDI-Classifier-Composition',\n",
        "                                                        track_name='Project Los Angeles',\n",
        "                                                        )\n",
        "\n",
        "print('=' * 70)\n",
        "print('Displaying resulting composition...')\n",
        "print('=' * 70)\n",
        "\n",
        "fname = '/content/Ultimate-MIDI-Classifier-Composition'\n",
        "\n",
        "if render_MIDI_to_audio:\n",
        "  midi_audio = midi_to_colab_audio(fname + '.mid')\n",
        "  display(Audio(midi_audio, rate=16000, normalize=False))\n",
        "\n",
        "TMIDIX.plot_ms_SONG(song_f, plot_title=fname)"
      ],
      "metadata": {
        "id": "jR7nuQpEtj3m",
        "cellView": "form"
      },
      "id": "jR7nuQpEtj3m",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Congrats! You did it! :)"
      ],
      "metadata": {
        "id": "R7__rVP0EVG7"
      },
      "id": "R7__rVP0EVG7"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "private_outputs": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}